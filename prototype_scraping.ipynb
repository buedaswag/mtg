{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import ElementNotInteractableException, ElementClickInterceptedException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import re\n",
    "import time\n",
    "from sqlalchemy import create_engine\n",
    "import pickle\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "from psycopg2.errors import UndefinedTable\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove_today_records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" test some scraping\\n\\ncard_name = 'Snow-Covered Island'\\nurl = 'https://www.cardmarket.com/en/Magic/Products/Singles/Throne-of-Eldraine/Questing-Beast'\\nurl = 'https://www.cardmarket.com/en/Magic/Products/Singles/Modern-Horizons/Snow-Covered-Island'\\nhtml = load_page(url, card_name, debug = True)\\ninfo, table = get_soup(html)\\n\\ntag=info.find_all('script', class_='chart-init-script')#[0].get_text().strip()\\nregex = r'Avg. Sell Price.*?]'\\nmatch = re.findall(regex, str(tag[0]))\\n\\nfloat(match[0][25:-1].split(',')[-1])\\n\\nnow = pd.Timestamp.now(tz='UTC') #Timestamp('2019-10-09 15:09:44.173350+0000')\\nminute = 0 \\nnow_date_time_hour = pd.Timestamp(now.year, now.month, now.day, now.hour, minute)\\n\\ndf = get_data(info, table, card_name, now, debug=False, debug_hard=False)\\n\\ndf\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' test some scraping\n",
    "\n",
    "card_name = 'Snow-Covered Island'\n",
    "url = 'https://www.cardmarket.com/en/Magic/Products/Singles/Throne-of-Eldraine/Questing-Beast'\n",
    "url = 'https://www.cardmarket.com/en/Magic/Products/Singles/Modern-Horizons/Snow-Covered-Island'\n",
    "html = load_page(url, card_name, debug = True)\n",
    "info, table = get_soup(html)\n",
    "\n",
    "tag=info.find_all('script', class_='chart-init-script')#[0].get_text().strip()\n",
    "regex = r'Avg. Sell Price.*?]'\n",
    "match = re.findall(regex, str(tag[0]))\n",
    "\n",
    "float(match[0][25:-1].split(',')[-1])\n",
    "\n",
    "now = pd.Timestamp.now(tz='UTC') #Timestamp('2019-10-09 15:09:44.173350+0000')\n",
    "minute = 0 \n",
    "now_date_time_hour = pd.Timestamp(now.year, now.month, now.day, now.hour, minute)\n",
    "\n",
    "df = get_data(info, table, card_name, now, debug=False, debug_hard=False)\n",
    "\n",
    "df\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sales_available_items(row_tag):\n",
    "    #tag=row_tag.find_all('span', class_='badge badge-faded d-none d-sm-inline-flex has-content-centered mr-1 sell-count')[0]#.get_text().strip()\n",
    "    regex = r'\\d+\\sSales\\s|\\s\\d+\\sAvailable\\sitems'\n",
    "    match = re.findall(regex, str(row_tag))\n",
    "    sales = match[0][:-7]\n",
    "    available_items = match[1][1:-16]\n",
    "    return sales, available_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_today_records():\n",
    "    engine = get_db_connection()\n",
    "    query = '''\n",
    "    DELETE \n",
    "    FROM card_listings\n",
    "    WHERE ts::date = now()::date;\n",
    "\n",
    "    '''\n",
    "\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeLimitExpired(Exception):\n",
    "    pass\n",
    "\n",
    "def load_page(url, card_name, debug = False):\n",
    "    '''\n",
    "    setup - load entire page, pressing 'show more' button\n",
    "    -------------------------------------\n",
    "    If debuf is True, tries to load an existing pickle containing html, \n",
    "    and if this file does not exist, loads the web page and stores the html as a pickle.\n",
    "    '''\n",
    "    \n",
    "    #fix card name\n",
    "    card_name = card_name.replace('/', '-')\n",
    "    \n",
    "    #load debug file\n",
    "    debug_path = Path(os.path.join(Path().absolute() , 'debug'))\n",
    "    pickle_file = Path(os.path.join(debug_path , '%s.pickle'%card_name))\n",
    "    if debug == True and pickle_file.is_file():\n",
    "        html = None\n",
    "        with open(pickle_file, 'rb') as file:\n",
    "            html = pickle.load(file)\n",
    "        return html\n",
    "    \n",
    "    driver = webdriver.Chrome('/usr/bin/chromedriver')\n",
    "    driver.get(url)\n",
    "    delay = 2\n",
    "    timeout = 0\n",
    "    html = None\n",
    "    try:\n",
    "        while True:\n",
    "            try:\n",
    "                driver.find_element_by_xpath(r\"//span[contains(text(),'Show more results')]\").click()\n",
    "                #reset timeout\n",
    "                timeout = 0\n",
    "                time.sleep(delay)\n",
    "            except ElementClickInterceptedException as e:\n",
    "                if timeout >= 60:\n",
    "                    raise TimeLimitExpired('timeout >= 60')\n",
    "                time.sleep(delay)\n",
    "                timeout += delay\n",
    "    except ElementNotInteractableException as e:\n",
    "        #now we have all the data, SCRAPE IT!!!\n",
    "        html = driver.page_source.encode('utf-8')\n",
    "        \n",
    "        #dump file for debug if no file exists\n",
    "        if not debug_path.is_dir():\n",
    "            os.makedirs(debug_path)\n",
    "        if pickle_file.is_file() == False:\n",
    "            with open(pickle_file, 'wb') as file:\n",
    "                pickle.dump(html, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    finally:\n",
    "        driver.quit()\n",
    "            \n",
    "    return html\n",
    "\n",
    "def get_soup(html):\n",
    "    '''\n",
    "    setup with selenium: get the html to scrape\n",
    "    '''\n",
    "\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    table_tag = soup.find_all('div', class_=\"table-body\")\n",
    "    table = table_tag[0]\n",
    "    info_tag = soup.find_all('div', class_='tab-container d-flex flex-column h-100')\n",
    "    info = info_tag[0]\n",
    "    \n",
    "    return info, table\n",
    "\n",
    "def get_sales_available_items(row_tag):\n",
    "    #tag=row_tag.find_all('span', class_='badge badge-faded d-none d-sm-inline-flex has-content-centered mr-1 sell-count')[0]#.get_text().strip()\n",
    "    regex = r'\\d+\\sSales\\s|\\s\\d+\\sAvailable\\sitems'\n",
    "    match = re.findall(regex, str(row_tag))\n",
    "    sales = match[0][:-7]\n",
    "    available_items = match[1][1:-16]\n",
    "    return sales, available_items\n",
    "\n",
    "def get_item_location(row_tag):\n",
    "    tag=row_tag.find_all('span', class_='icon d-flex has-content-centered mr-1')[0]\n",
    "    regex = r'\\\"Item\\slocation:\\s.*?\\\"'\n",
    "    match = re.findall(regex, str(tag))\n",
    "    item_location = match[0][16:-1]\n",
    "    return item_location\n",
    "\n",
    "def get_product_information(row_tag):\n",
    "    tag=row_tag.find_all('div', class_='product-attributes col-auto col-md-12 col-xl-5')[0]#.get_text().strip()\n",
    "    regex = r'showMsgBox\\(this,\\'.*?\\'\\)'\n",
    "    match = re.findall(regex, str(tag))\n",
    "    \n",
    "    item_conditions = match[0][17:-2]\n",
    "    item_languages = match[1][17:-2]\n",
    "    \n",
    "    item_is_playset = False\n",
    "    for item in match:\n",
    "        if item[17:-2] == 'Playset':\n",
    "            item_is_playset = True\n",
    "\n",
    "    item_is_foil = False\n",
    "    for item in match:\n",
    "        if item[17:-2] == 'Foil':\n",
    "            item_is_foil = True\n",
    "    return item_conditions, item_languages, item_is_playset, item_is_foil\n",
    "\n",
    "def get_avg_sell_price(info):\n",
    "    '''\n",
    "    get avg_sell_price\n",
    "    '''\n",
    "    tag=info.find_all('script', class_='chart-init-script')#[0].get_text().strip()\n",
    "    regex = r'Avg. Sell Price.*?]'\n",
    "    match = re.findall(regex, str(tag[0]))\n",
    "    avg_sell_price = float(match[0][25:-1].split(',')[-1])\n",
    "    \n",
    "    return avg_sell_price\n",
    "\n",
    "def get_item_info(info):\n",
    "    '''\n",
    "    get item_info\n",
    "    \n",
    "    Available items\n",
    "    From\n",
    "    Price Trend\n",
    "    30-days average price\n",
    "    7-days average price\n",
    "    1-day average price\n",
    "    '''\n",
    "    \n",
    "    tag=info.find_all('dd', class_='col-6 col-xl-7')#[0].get_text().strip()\n",
    "    item_info = [t.get_text() for t in tag[3:]]\n",
    "    return item_info\n",
    "\n",
    "def get_data(info, table, card_name, now, debug=False, debug_hard=False):\n",
    "    '''\n",
    "    iterate through each row in the table, getting the data\n",
    "    '''\n",
    "    \n",
    "    row_tags = table.find_all('div', class_='row no-gutters article-row')\n",
    "    \n",
    "    seller_names = []\n",
    "    item_prices = []\n",
    "    item_amounts = [] \n",
    "    seller_sales = []\n",
    "    seller_available_items = []\n",
    "    item_locations = []\n",
    "    item_conditions = []\n",
    "    item_languages = []\n",
    "    item_is_playsets = []\n",
    "    item_is_foils = []\n",
    "    avg_sell_price = get_avg_sell_price(info)\n",
    "    \n",
    "    for row_tag in row_tags:\n",
    "        seller_names.append(row_tag.find_all('span', class_='d-flex has-content-centered mr-1')[0].get_text().strip())\n",
    "\n",
    "        item_prices.append(row_tag.find_all('span', class_='font-weight-bold color-primary small text-right text-nowrap')[0].get_text().strip()[:-2])\n",
    "\n",
    "        item_amounts.append(row_tag.find_all('span', class_='item-count small text-right')[0].get_text().strip()[:])\n",
    "        \n",
    "        sales, available_items = get_sales_available_items(row_tag)\n",
    "        seller_sales.append(sales)\n",
    "        seller_available_items.append(available_items)\n",
    "\n",
    "        item_locations.append(get_item_location(row_tag))\n",
    "\n",
    "        item_condition, item_language, item_is_playset, item_is_foil= get_product_information(row_tag)\n",
    "        item_conditions.append(item_condition)\n",
    "        item_languages.append(item_language)\n",
    "        item_is_playsets.append(item_is_playset)\n",
    "        item_is_foils.append(item_is_foil)\n",
    "    \n",
    "    '''\n",
    "    put it into pandas\n",
    "    '''\n",
    "    data_dict = {\n",
    "        'card_name': [card_name for i in range(len(seller_names))],\n",
    "        'ts': [now for i in range(len(seller_names))],\n",
    "        'avg_sell_price': [avg_sell_price for i in range(len(seller_names))], \n",
    "        'seller_name': seller_names,\n",
    "        'seller_sales': seller_sales,\n",
    "        'seller_available_items': seller_available_items,\n",
    "        'item_price': item_prices,\n",
    "        'item_amount': item_amounts,\n",
    "        'item_location': item_locations,\n",
    "        'item_condition': item_conditions,\n",
    "        'item_language': item_languages,\n",
    "        'item_is_playset': item_is_playsets,\n",
    "        'item_is_foil': item_is_foils,\n",
    "    }\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    \n",
    "    '''\n",
    "    change some datatypes\n",
    "    '''\n",
    "    df.seller_sales = df.seller_sales.astype(int)\n",
    "    df.seller_available_items = df.seller_available_items.astype(int)\n",
    "    df.item_amount = df.item_amount.astype(int)\n",
    "    df.item_price = df.item_price.str.replace('.', '')\n",
    "    df.item_price = df.item_price.str.replace(',', '.')\n",
    "    df.item_price = df.item_price.astype(float)\n",
    "    \n",
    "    '''\n",
    "    make some replacements\n",
    "    '''\n",
    "    df.item_condition = df.item_condition.replace(\n",
    "        {'Mint': 'M', 'Near Mint': 'NM', 'Excellent': 'EX', \n",
    "         'Good': 'GD', 'Light Played': 'LP', 'Played': 'PL', 'Poor': 'P'})\n",
    "\n",
    "    '''\n",
    "    correct for playsets:\n",
    "    '''\n",
    "    df.loc[df.item_is_playset == True, 'item_price'] = \\\n",
    "        df.loc[df.item_is_playset == True, 'item_price'] / 4\n",
    "    df.loc[df.item_is_playset == True, 'item_amount'] = \\\n",
    "        df.loc[df.item_is_playset == True, 'item_amount'] * 4\n",
    "\n",
    "    if debug_hard == True:\n",
    "        with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "            display(df)\n",
    "    return df\n",
    "\n",
    "''' \n",
    "bitconnect to the database \n",
    "'''\n",
    "def get_db_connection():\n",
    "    username = 'mig'\n",
    "    password = 'password' \n",
    "    host_name = 'localhost'\n",
    "    port = 5432\n",
    "    db_name = 'mtg'\n",
    "    conn_str = 'postgresql://{}:{}@{}:{}/{}'.format(username, password, host_name, port, db_name)\n",
    "\n",
    "    engine = create_engine(conn_str)\n",
    "    return engine\n",
    "\n",
    "def conditional_insert(engine, card_name, debug = False):\n",
    "    '''\n",
    "    Checks if its time to insert records in the database.\n",
    "    We only want to insert records with a frequency of frequency.\n",
    "    \n",
    "    engine - the db engine\n",
    "    card_name - the card name\n",
    "    frequency - the frequency of db inserts\n",
    "    '''\n",
    "    \n",
    "    now = pd.Timestamp.now(tz='UTC') #Timestamp('2019-10-09 15:09:44.173350+0000')\n",
    "    \n",
    "    '''\n",
    "    for example, inserting every 30 minutes:\n",
    "    minute = 0 if now.minute < 30 else 30\n",
    "    \n",
    "    inserting every hour:\n",
    "    minute = 0 \n",
    "    '''\n",
    "    minute = 0 \n",
    "    \n",
    "    now_date_time_hour = pd.Timestamp(now.year, now.month, now.day, now.hour, minute)\n",
    "    \n",
    "    if debug == True:\n",
    "        with engine.connect() as conn:\n",
    "            print('timezone: %s' % (conn.execute('show timezone;').fetchall()[0],))\n",
    "\n",
    "    query = '''\n",
    "    SELECT COUNT(*)  \n",
    "    FROM card_listings\n",
    "    WHERE card_name = '%s' \n",
    "    AND ts::time = '%s'::time \n",
    "    AND ts::date = '%s'::date;\n",
    "    '''%(card_name, now_date_time_hour, now_date_time_hour)\n",
    "    \n",
    "    df_result = pd.read_sql_query(query, engine)\n",
    "    \n",
    "    if debug==True:\n",
    "        print(query)\n",
    "    \n",
    "    return df_result.iloc[0][0], now_date_time_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------\n",
      "inserting records of card Snow Covered Island with shape (1326, 13) at 2019-11-10 18:00:00\n",
      "head: \n",
      "             card_name                  ts  avg_sell_price seller_name  \\\n",
      "0  Snow Covered Island 2019-11-10 18:00:00            0.46     Drainer   \n",
      "\n",
      "   seller_sales  seller_available_items  item_price  item_amount  \\\n",
      "0           887                     107        0.05            1   \n",
      "\n",
      "  item_location item_condition item_language  item_is_playset  item_is_foil  \n",
      "0       Germany             NM        German            False         False  \n",
      "inserting records of card Fabled Passage with shape (632, 13) at 2019-11-10 18:00:00\n",
      "head: \n",
      "        card_name                  ts  avg_sell_price seller_name  \\\n",
      "0  Fabled Passage 2019-11-10 18:00:00           14.94      Jowiii   \n",
      "\n",
      "   seller_sales  seller_available_items  item_price  item_amount  \\\n",
      "0            36                      12        12.0            1   \n",
      "\n",
      "  item_location item_condition item_language  item_is_playset  item_is_foil  \n",
      "0         Spain              M       Spanish            False         False  \n",
      "inserting records of card Once Upon a Time with shape (751, 13) at 2019-11-10 18:00:00\n",
      "head: \n",
      "          card_name                  ts  avg_sell_price seller_name  \\\n",
      "0  Once Upon a Time 2019-11-10 18:00:00           14.52      milaya   \n",
      "\n",
      "   seller_sales  seller_available_items  item_price  item_amount  \\\n",
      "0           438                      88        13.2            1   \n",
      "\n",
      "  item_location item_condition item_language  item_is_playset  item_is_foil  \n",
      "0        France             NM        French            False         False  \n",
      "inserting records of card Murderous Rider // Swift End with shape (1331, 13) at 2019-11-10 18:00:00\n",
      "head: \n",
      "                      card_name                  ts  avg_sell_price  \\\n",
      "0  Murderous Rider // Swift End 2019-11-10 18:00:00            5.93   \n",
      "\n",
      "  seller_name  seller_sales  seller_available_items  item_price  item_amount  \\\n",
      "0      shkoBo             1                       2         4.5            1   \n",
      "\n",
      "  item_location item_condition item_language  item_is_playset  item_is_foil  \n",
      "0      Slovenia             NM       English            False         False  \n",
      "inserting records of card Questing Beast with shape (613, 13) at 2019-11-10 18:00:00\n",
      "head: \n",
      "        card_name                  ts  avg_sell_price   seller_name  \\\n",
      "0  Questing Beast 2019-11-10 18:00:00           19.25  Devilgoat666   \n",
      "\n",
      "   seller_sales  seller_available_items  item_price  item_amount  \\\n",
      "0            29                       1        16.0            1   \n",
      "\n",
      "  item_location item_condition item_language  item_is_playset  item_is_foil  \n",
      "0       Germany             NM        German            False         False  \n",
      "inserting records of card Oko, Thief of Crowns with shape (709, 13) at 2019-11-10 18:00:00\n",
      "head: \n",
      "              card_name                  ts  avg_sell_price seller_name  \\\n",
      "0  Oko, Thief of Crowns 2019-11-10 18:00:00           31.07     ikayami   \n",
      "\n",
      "   seller_sales  seller_available_items  item_price  item_amount  \\\n",
      "0             2                       2       24.99            1   \n",
      "\n",
      "  item_location item_condition item_language  item_is_playset  item_is_foil  \n",
      "0       Ireland             NM       English            False         False  \n",
      "start: 2019-11-10 18:50:57.556543+00:00\n",
      "end: 2019-11-10 18:56:20.002204+00:00\n",
      "duration: 0 days 00:05:22.445661\n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def main(engine, debug=False, debug_hard=False):\n",
    "    '''\n",
    "    the 6 debug files have 14.5 MB total\n",
    "    14.5MB x 2 times per hour x 24 hours x 31 days = 21576 GB per month\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    card_names and links\n",
    "    '''\n",
    "    card_names_urls = {\n",
    "            'Snow Covered Island': 'https://www.cardmarket.com/en/Magic/Products/Singles/Modern-Horizons/Snow-Covered-Island', \n",
    "            'Fabled Passage': 'https://www.cardmarket.com/en/Magic/Products/Singles/Throne-of-Eldraine/Fabled-Passage', \n",
    "            'Once Upon a Time': 'https://www.cardmarket.com/en/Magic/Products/Singles/Throne-of-Eldraine/Once-Upon-a-Time', \n",
    "            'Murderous Rider // Swift End': 'https://www.cardmarket.com/en/Magic/Products/Singles/Throne-of-Eldraine/Murderous-Rider-Swift-End', \n",
    "            'Questing Beast': 'https://www.cardmarket.com/en/Magic/Products/Singles/Throne-of-Eldraine/Questing-Beast', \n",
    "            'Oko, Thief of Crowns': 'https://www.cardmarket.com/en/Magic/Products/Singles/Throne-of-Eldraine/Oko-Thief-of-Crowns'\n",
    "    }\n",
    "    \n",
    "    for card_name in card_names_urls:  \n",
    "        \n",
    "        '''\n",
    "        checks if its time to insert data for this card, and skips it if its not\n",
    "        '''\n",
    "        count, now = conditional_insert(engine, card_name, debug=debug)\n",
    "        if count > 0:\n",
    "            print('There are already %d records at %s'%(count, now))\n",
    "            continue\n",
    "        \n",
    "        url = card_names_urls[card_name]\n",
    "        html = load_page(url, card_name, debug=debug)\n",
    "        info, table = get_soup(html)\n",
    "        df = get_data(info, table, card_name, now, debug_hard=debug_hard)\n",
    "        \n",
    "        print('inserting records of card %s with shape %s at %s'%(card_name, str(df.shape), str(now)))\n",
    "        print('head: ')\n",
    "        with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "            print(df.head(1))\n",
    "        \n",
    "        df.to_sql('card_listings', con=engine, if_exists='append', index=False)\n",
    "        \n",
    "        if debug == True:\n",
    "            print(card_name)\n",
    "            print(card_names_urls[card_name])\n",
    "            print(df.shape)\n",
    "            print(df.dtypes)\n",
    "            \n",
    "        if debug_hard == True:\n",
    "            with pd.option_context('display.max_rows', None, 'display.max_columns', 20):  # more options can be specified also\n",
    "                display(df)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    print('-----------------------------------------------------------------------------')\n",
    "    start = pd.Timestamp.now(tz='UTC') #Timestamp('2019-10-09 15:09:44.173350+0000')    \n",
    "    try: \n",
    "        engine = get_db_connection()\n",
    "        \n",
    "        main(engine, debug=False, debug_hard=False)\n",
    "        \n",
    "        \n",
    "    finally:\n",
    "        engine.dispose()\n",
    "        end = pd.Timestamp.now(tz='UTC')\n",
    "        print('start: %s'%(start,))\n",
    "        print('end: %s'%(end,))\n",
    "        print('duration: %s'%(end - start,))\n",
    "    print('-----------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook prototype_scraping.ipynb to script\n",
      "[NbConvertApp] Writing 14173 bytes to prototype_scraping.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script prototype_scraping.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
